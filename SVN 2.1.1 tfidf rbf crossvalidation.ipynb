{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from IPython.display import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Pandas provide a .read_csv() function. the paramter engine='python' was needed here.\n",
    "We can see in the output that there are two columns \"text\" and \"spam\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  spam\n",
      "0     Subject: naturally irresistible your corporate...     1\n",
      "1     Subject: the stock trading gunslinger  fanny i...     1\n",
      "2     Subject: unbelievable new homes made easy  im ...     1\n",
      "3     Subject: 4 color printing special  request add...     1\n",
      "4     Subject: do not have money , get software cds ...     1\n",
      "5     Subject: great nnews  hello , welcome to medzo...     1\n",
      "6     Subject: here ' s a hot play in motion  homela...     1\n",
      "7     Subject: save your money buy getting this thin...     1\n",
      "8     Subject: undeliverable : home based business f...     1\n",
      "9     Subject: save your money buy getting this thin...     1\n",
      "10    Subject: las vegas high rise boom  las vegas i...     1\n",
      "11    Subject: save your money buy getting this thin...     1\n",
      "12    Subject: brighten those teeth  get your  teeth...     1\n",
      "13    Subject: wall street phenomenon reaps rewards ...     1\n",
      "14    Subject: fpa notice : ebay misrepresentation o...     1\n",
      "15    Subject: search engine position  be the very f...     1\n",
      "16    Subject: only our software is guaranteed 100 %...     1\n",
      "17    Subject: localized software , all languages av...     1\n",
      "18    Subject: security alert - confirm your nationa...     1\n",
      "19    Subject: 21 st century web specialists jrgbm  ...     1\n",
      "20    Subject: any med for your girl to be happy !  ...     1\n",
      "21    Subject: re : wearable electronics  hi my name...     1\n",
      "22    Subject: top - level logo and business identit...     1\n",
      "23    Subject: your trusted source for prescription ...     1\n",
      "24    Subject: rely on us for your online prescripti...     1\n",
      "25    Subject: guzzle like a fountain  spur m rocks ...     1\n",
      "26    Subject: are you losing ? the answer would ama...     1\n",
      "27    Subject: hi  how to save o improper n your med...     1\n",
      "28    Subject: 25 mg did thhe trick  ho receivable w...     1\n",
      "29    Subject: save your money buy getting this thin...     1\n",
      "...                                                 ...   ...\n",
      "5698  Subject: schedule and more . .  dr . kaminski ...     0\n",
      "5699  Subject: re : message from ken rice  vince :  ...     0\n",
      "5700  Subject: re : exploration data as the root of ...     0\n",
      "5701  Subject: rendez - vous reporter : sunday 3 rd ...     0\n",
      "5702  Subject: dr . michelle foss - energy institute...     0\n",
      "5703  Subject: rice / enron finance seminar series  ...     0\n",
      "5704  Subject: storage model security  stinson ,  i ...     0\n",
      "5705  Subject: re : meeting w kevin hannon  vince an...     0\n",
      "5706  Subject: e - mail and voicemail retention poli...     0\n",
      "5707  Subject: approval is overdue : access request ...     0\n",
      "5708  Subject: re : hi vince  hi jeff ,  no problem ...     0\n",
      "5709  Subject: agenda for larry thorne ' s presentat...     0\n",
      "5710  Subject: raptors  here is the most recent vers...     0\n",
      "5711  Subject: re : faculty lunch  alison ,  i recom...     0\n",
      "5712  Subject: 2 - survey / information email 5 - 7 ...     0\n",
      "5713  Subject: promotion  vince , i want to congratu...     0\n",
      "5714  Subject: re : petronas benchmarking visit  fyi...     0\n",
      "5715  Subject: request submitted : access request fo...     0\n",
      "5716  Subject: * special notification * aurora versi...     0\n",
      "5717  Subject: fwd : update  return - path :  receiv...     0\n",
      "5718  Subject: altos na gas model  kim , i know you ...     0\n",
      "5719  Subject: power market research  i came across ...     0\n",
      "5720  Subject: re : visit to houston  fyi  - - - - -...     0\n",
      "5721  Subject: ees risk management presentations for...     0\n",
      "5722  Subject: re : vacation  vince :  i just found ...     0\n",
      "5723  Subject: re : research and development charges...     0\n",
      "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
      "5725  Subject: re : enron case study update  wow ! a...     0\n",
      "5726  Subject: re : interest  david ,  please , call...     0\n",
      "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
      "\n",
      "[5728 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/shreyansh/Downloads/emails.csv', encoding='latin-1', engine='python')\n",
    "data.head(n=10)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer (text):\n",
    "    text = text.split()\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5728, 29101)\n",
      "  (0, 25144)\t0.018320780122310316\n",
      "  (0, 18486)\t0.0774666020541566\n",
      "  (0, 14727)\t0.14736976038474162\n",
      "  (0, 8307)\t0.07050131715310318\n",
      "  (0, 14000)\t0.0938151598024009\n",
      "  (0, 16675)\t0.11580733234546622\n",
      "  (0, 22001)\t0.07011905153908338\n",
      "  (0, 13168)\t0.08063017188146154\n",
      "  (0, 22083)\t0.11454332911694699\n",
      "  (0, 7890)\t0.1626189570288924\n",
      "  (0, 17093)\t0.2048836446936474\n",
      "  (0, 25314)\t0.12724232620438508\n",
      "  (0, 14361)\t0.043518406160338516\n",
      "  (0, 14766)\t0.13875892723664263\n",
      "  (0, 12687)\t0.10557755235592851\n",
      "  (0, 6943)\t0.11788360227052634\n",
      "  (0, 16521)\t0.35477178806462895\n",
      "  (0, 25125)\t0.12724232620438508\n",
      "  (0, 24867)\t0.12605993014920455\n",
      "  (0, 19665)\t0.0938151598024009\n",
      "  (0, 28031)\t0.13683433125504949\n",
      "  (0, 16922)\t0.09319476031976016\n",
      "  (0, 25653)\t0.09482761518737638\n",
      "  (0, 10162)\t0.09546308166869215\n",
      "  (0, 21334)\t0.1759258777737806\n",
      "  :\t:\n",
      "  (5727, 21686)\t0.04263369319795056\n",
      "  (5727, 14432)\t0.11220093044304848\n",
      "  (5727, 26243)\t0.09695542166571573\n",
      "  (5727, 24064)\t0.03723293891927914\n",
      "  (5727, 6840)\t0.04151787470261093\n",
      "  (5727, 9730)\t0.056103813622326075\n",
      "  (5727, 19653)\t0.13257832514857823\n",
      "  (5727, 11206)\t0.05470052210886527\n",
      "  (5727, 2134)\t0.15252243839105836\n",
      "  (5727, 24768)\t0.055762075276051246\n",
      "  (5727, 9995)\t0.055762075276051246\n",
      "  (5727, 18015)\t0.04319774812584689\n",
      "  (5727, 5086)\t0.5624816170501258\n",
      "  (5727, 2807)\t0.17782372450160447\n",
      "  (5727, 10551)\t0.1084371321662828\n",
      "  (5727, 15992)\t0.0542185660831414\n",
      "  (5727, 16144)\t0.06800836642866123\n",
      "  (5727, 27426)\t0.05767927497109912\n",
      "  (5727, 7407)\t0.06394738460161366\n",
      "  (5727, 10803)\t0.328606700330799\n",
      "  (5727, 28162)\t0.06572134006615979\n",
      "  (5727, 943)\t0.13144268013231958\n",
      "  (5727, 2776)\t0.06572134006615979\n",
      "  (5727, 13915)\t0.07123174904480703\n",
      "  (5727, 26364)\t0.07123174904480703\n"
     ]
    }
   ],
   "source": [
    "f = TfidfVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(data[\"text\"])\n",
    "print(np.shape(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['spam'], test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\n",
      "[0.001 0.002 0.003 0.004 0.005]\n",
      "[{'gamma': array([0.001, 0.002, 0.003, 0.004, 0.005]), 'C': array([800])}]\n"
     ]
    }
   ],
   "source": [
    "list_C = np.arange(800,900,100)\n",
    "list_gamma = np.arange(0.001,0.006,0.001)\n",
    "parameters = [{'gamma': list_gamma,\n",
    "                     'C': list_C}]\n",
    "print(list_C)\n",
    "print(list_gamma)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 800, 'gamma': 0.001}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='rbf')\n",
    "gridsearch = GridSearchCV(svc, parameters, cv=2, scoring='f1', n_jobs=-1)\n",
    "gridsearch.fit(X_train,y_train)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803859402162253"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>1274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>14</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         1274            4\n",
       "Actual 1           14          427"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, gridsearch.best_estimator_.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
